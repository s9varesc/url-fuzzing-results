{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Figures and Tables for Latex from ExperimentResults.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install pandas markdown matplotlib import-ipynb\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import display, Markdown\n",
    "from ExperimentResults import *;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(loc, indexcol):\n",
    "    return pd.read_csv(loc, index_col=indexcol).rename(columns=str.lower)\n",
    "\n",
    "def readCSVs(folder, indexcol):\n",
    "    df_main=readCSV(folder+\"/experimentResultsMain.csv\", indexcol='run_nr')\n",
    "    df_comp=readCSV(folder+\"/experimentResultsComponents.csv\", indexcol='run_nr')\n",
    "    return (df_main, df_comp)\n",
    "\n",
    "def aligned(df1, df1_comp, df2, df2_comp):\n",
    "    length1=df1.index.max()+1\n",
    "    length2=df2.index.max()+1\n",
    "\n",
    "    if length1 != length2:\n",
    "        if length1>length2: #more df1 results than df2 results\n",
    "            df1=df1[:length2]\n",
    "            df1_comp=df1_comp[:length2]\n",
    "        else: #more rfc than ls results\n",
    "            df2=df2[:length1]\n",
    "            df2_comp=df2_comp[:length1]\n",
    "    return (df1, df1_comp, df2, df2_comp)\n",
    "\n",
    "def readAndAlignCSVs(folder1, folder2, indexcol):\n",
    "    df1, df1_comp=readCSVs(folder1, indexcol)\n",
    "    df2, df2_comp=readCSVs(folder2, indexcol)\n",
    "    return aligned(df1, df1_comp, df2, df2_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs={}\n",
    "plots=[]\n",
    "for parser in sorted(parsers):\n",
    "    dfs[parser], plot=compareGrammarResults(parser, ls_df, \"Living Standard\", rfc_df, \"RFC\")\n",
    "    plots+=[plot]\n",
    "    \n",
    "\n",
    "# focusing on a range\n",
    "#for parser in parsers:\n",
    "#    dfs[parser]=compareGrammarResults(parser, ls_df, \"Living Standard\", rfc_df, \"RFC\", (0,10))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below are used to create data representations in latex-friendly formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMultiOverview(dfs, parsers, pdfname, includeOther=False):\n",
    "    ffexcov=74.7 \n",
    "    ffwptcov=84.4\n",
    "    chrexcov=82.71\n",
    "    chrwptcov=64.29\n",
    "    \n",
    "    plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    plt.rcParams['xtick.minor.size'] = 0\n",
    "    plt.rcParams['xtick.minor.width'] = 0\n",
    "    \n",
    "    \n",
    "    figure, axs = plt.subplots(6,2, figsize=(40,60))\n",
    "    plot_index=0\n",
    "    axs[-1, -1].axis('off')\n",
    "    for loc in axs.flat:\n",
    "        try:\n",
    "            new_df=dfs[parsers[plot_index]]\n",
    "            plot_index+=1\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        name=parsers[plot_index-1].replace('script', 'script ')\n",
    "        \n",
    "        plot=new_df.plot(title=name.capitalize()+\"\\n\",ylim=(0,100),\n",
    "                         ax=loc, style=\".\", color=colors_comp, ms=ms/2, legend=False, logx=True)\n",
    "        plot.set_xscale('symlog', linthreshx=1, linscalex=0.08)\n",
    "        \n",
    "        plot.margins(x=0.025)\n",
    "        \n",
    "        xlim=dfs[parsers[plot_index-1]].index.max()\n",
    "        if includeOther:\n",
    "            if parsers[plot_index-1]=='firefox': \n",
    "                plot.hlines(y=ffexcov, xmin=0, xmax=xlim, color='black', linestyle=':', lw=4, label='Existing Test Files')\n",
    "                plot.hlines(y=ffwptcov, xmin=0, xmax=xlim, color='y', linestyle=':', lw=4, label='WPT tests')\n",
    "            if parsers[plot_index-1]=='chromium':\n",
    "                plot.hlines(y=chrexcov, xmin=0, xmax=xlim, color='black', linestyle=':', lw=4, label='Existing Test Files')\n",
    "                plot.hlines(y=chrwptcov, xmin=0, xmax=xlim, color='y', linestyle=':', lw=4, label='WPT tests')\n",
    "                \n",
    "            \n",
    "        vals = loc.get_yticks()\n",
    "        loc.set_yticklabels(['{:.0f}'.format(x)+\"%\" for x in vals])\n",
    "        plot.grid(True)\n",
    "        plot.set_xlabel(\"Run\")\n",
    "        #plot.legend(loc='best',markerscale=2.)\n",
    "\n",
    "    use_labels=[]\n",
    "    use_handles=None\n",
    "    for ax in figure.get_axes():\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        if len(labels)>len(use_labels):\n",
    "            use_labels=labels\n",
    "            use_handles=handles\n",
    "        if ax != axs[4][1]:\n",
    "            if ax != axs[5][0]:\n",
    "                ax.label_outer()\n",
    "            else:\n",
    "                valsx = ax.get_xticks()\n",
    "                ax.set_xticklabels(['{:.0f}'.format(x) for x in valsx])\n",
    "        else:\n",
    "            ax.set_yticklabels(['' for x in vals])\n",
    "            valsx = ax.get_xticks()\n",
    "            ax.set_xticklabels(['{:.0f}'.format(x) for x in valsx])\n",
    "            #handles, labels = ax.get_legend_handles_labels()\n",
    "            figure.legend(use_handles, use_labels, loc=(0.6,0.1), markerscale=4.)\n",
    "\n",
    "\n",
    "\n",
    "    plt.savefig(pdfname)\n",
    "#'ov_detail.pdf'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_table(comp_df, b_df, steps=100, components=['success', 'scheme', 'username', \n",
    "                                                            'password', 'host', 'port', 'path', \n",
    "                                                            'query', 'fragment', 'reject']):\n",
    "    tab_df=comp_df\n",
    "    col=b_df['nr-inputs']\n",
    "    tab_df['nr_inputs_unique']=col\n",
    "    \n",
    "    runs=tab_df.index.max()\n",
    "    f='l'\n",
    "    #make sure table fits on latex page: 1st column p{3.1cm}, 12+1 entries\n",
    "    while runs//steps>=11:\n",
    "        f='p{3.1cm}'\n",
    "        steps+=4\n",
    "    tab_df=tab_df.reindex(sorted(tab_df.columns), axis=1)\n",
    "    last_elem=tab_df.tail(1)\n",
    "    tab_df=tab_df[::steps].append(last_elem).transpose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for c in tab_df.columns:\n",
    "        f+='r'\n",
    "    table=tab_df.to_latex(column_format=f, float_format=\"{:.0f}\".format)\n",
    "    for col in comp_df.columns:\n",
    "        for comp in components:\n",
    "            if col.count(comp)>1:\n",
    "                tcol=col.replace('_', '\\_')\n",
    "                table=table.replace(tcol, '\\\\textbf{'+tcol+'}')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fixCapitalization(text, find=[], replacement=[]):\n",
    "    newtext=''\n",
    "    for line in text.split('\\n'):\n",
    "        for (s, r) in zip(find, replacement):\n",
    "            line=line.replace(s, r)\n",
    "        newtext+='\\n'+line.capitalize()\n",
    "    return newtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaxCovBarDiagram(dfs, pdfname):   \n",
    "    plt.rcParams['font.size']='40'\n",
    "    figx, figy=(35,20)\n",
    "    labelrot=0\n",
    "    \n",
    "    columns=['Living Standard', \"RFC\"]\n",
    "    columns2=['Living Standard', 'ls max run', \"RFC\", 'rfc max run']\n",
    "    try:\n",
    "        test=dfs[parsers[0]].tail(1)['RFC'].iloc[0]\n",
    "    except:\n",
    "        columns=['Living Standard']\n",
    "        columns2=['Living Standard', 'ls max run']\n",
    "        figx=30\n",
    "        figy=15\n",
    "        #labelrot=15\n",
    "    \n",
    "    \n",
    "    overview_df=pd.DataFrame(index=[d for d in dfs], columns=columns)\n",
    "    for p in dfs:\n",
    "        for c in columns:\n",
    "            overview_df.loc[p][c]=dfs[p].tail(1)[c].iloc[0]\n",
    "    \n",
    "    fig, axs=plt.subplots(figsize=(figx,figy)) \n",
    "    \n",
    "    overview_df=overview_df.sort_index()  \n",
    "    plot=overview_df.plot(kind='bar', title=\"\",ylim=(0,100),\n",
    "                          color=colors_comp, ax=axs)#, alpha=0.85\n",
    "    plot.grid(True, alpha=0.5, zorder=2)\n",
    "    \n",
    "    display(overview_df)\n",
    "    #axs.set_ylabel(\"Coverages\", fontsize=40)\n",
    "    vals = axs.get_yticks()\n",
    "    axs.set_yticklabels(['{:.0f}'.format(x)+\"%\" for x in vals])\n",
    "    \n",
    "    labels = [item.get_text() for item in axs.get_xticklabels()]\n",
    "    blabels=[]\n",
    "    for label in labels:\n",
    "        if len(columns)<2:\n",
    "            label=label.replace('javascript', 'JS\\n')\n",
    "        blabels+=[\"\\n\"+label.replace('script', 'script\\n').capitalize()]\n",
    "    axs.set_xticklabels(blabels)\n",
    "    plt.xticks(rotation=labelrot, horizontalalignment=\"center\")\n",
    "    axs.set_axisbelow(True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in plot.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down +i.get_width()/6\n",
    "        \n",
    "        plot.text(i.get_x()+i.get_width()//2+0.055, i.get_height()+0.5, \n",
    "            str(i.get_height())+'%', fontsize=40,\n",
    "                  horizontalalignment=\"left\",\n",
    "                  verticalalignment=\"bottom\", rotation='vertical', \n",
    "                  family='sans serif', color='black', zorder=3)\n",
    "    \n",
    "    \n",
    "    plt.savefig(pdfname)#'ov_max_bar.pdf'\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    overview_df=pd.DataFrame(index=[d for d in dfs], columns=columns2)\n",
    "    for p in dfs:\n",
    "        overview_df.loc[p]['Living Standard']=dfs[p].tail(1)['Living Standard'].iloc[0]\n",
    "        overview_df.loc[p]['ls max run']=dfs[p]['Living Standard'].idxmax()\n",
    "        if len(columns2) >2:\n",
    "            overview_df.loc[p]['RFC']=dfs[p].tail(1)['RFC'].iloc[0]\n",
    "            overview_df.loc[p]['rfc max run']=dfs[p]['RFC'].idxmax()\n",
    "    \n",
    "    for c in overview_df.columns:\n",
    "        overview_df[c]=pd.to_numeric(overview_df[c])\n",
    "   \n",
    "    display(overview_df.describe())\n",
    "    return overview_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCovRunTable(overview_df):\n",
    "    for col in overview_df.columns:\n",
    "        display(overview_df.sort_values(by=col, ascending=False))\n",
    "\n",
    "    overview_df=overview_df.sort_values(by='Living Standard', ascending=False)\n",
    "    print(fixCapitalization(overview_df.to_latex(column_format='lcccc',float_format=\"{:.2f}%\".format), ['script', '.00'], ['script ', '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createComponentErrorPercentageTable(ls_df, ls_df_comp, rfc_df, rfc_df_comp):\n",
    "    err_df=browserComponentDetail('firefox', ls_df_comp, abs_inputs=int(ls_df.tail(1)['nr-inputs']), \n",
    "                                 components=['success', 'scheme', 'username', 'password', 'host',\n",
    "                                             'port', 'path', 'query', 'fragment', 'reject'])\n",
    "    if rfc_df_comp is not None:\n",
    "        err_df3=browserComponentDetail('firefox', rfc_df_comp, abs_inputs=int(rfc_df.tail(1)['nr-inputs']), \n",
    "                                     components=['success', 'reject'])\n",
    "        err_df['firefox rfc']=err_df3['firefox']\n",
    "\n",
    "    err_df2=browserComponentDetail('chromium', ls_df_comp,abs_inputs=int(ls_df.tail(1)['nr-inputs']), \n",
    "                                 components=['success', 'scheme', 'username', 'password', 'host',\n",
    "                                             'port', 'path', 'query', 'fragment', 'reject'])\n",
    "    err_df['chromium']=err_df2['chromium']\n",
    "    \n",
    "    if rfc_df_comp is not None:\n",
    "        err_df4=browserComponentDetail('chromium', rfc_df_comp,abs_inputs=int(rfc_df.tail(1)['nr-inputs']), \n",
    "                                     components=['success', 'reject'])\n",
    "        err_df['chromium rfc']=err_df4['chromium']\n",
    "    display(err_df)\n",
    "\n",
    "    inputsls=int(ls_df.tail(1)['nr-inputs'].max())\n",
    "    \n",
    "    rfccap=' unique inputs'\n",
    "    if rfc_df is not None:\n",
    "        inputsrfc=int(rfc_df.tail(1)['nr-inputs'].max())\n",
    "        rfccap=' (Living Standard-based) and '+str(inputsrfc)+'(RFC-based) unique inputs'\n",
    "        print(str(ls_df.tail(1).index.max())+\" = \"+str(rfc_df.tail(1).index.max()))\n",
    "    caption='for run '+str(ls_df.tail(1).index.max())+' with '+str(inputsls)+rfccap\n",
    "    \n",
    "    \n",
    "    print(err_df.to_latex(column_format='lcccc',\n",
    "        float_format=\"{:.2%}\".format).replace(\"nan\\%\", \"-\").replace('.00',''))\n",
    "    print('\\caption[Browser component errors]{Browser component errors '+caption+'}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createErrorPercentageTable(ls_df, rfc_df):\n",
    "    e_f_df=pd.DataFrame()\n",
    "    \n",
    "    e_df=errorsOverviewPlot(ls_df, \"Living Standard Exceptions Overview\\n\")\n",
    "    e_f_df['Living Standard']=e_df.tail(1).transpose()[ls_df.tail(1).index.max()]\n",
    "    \n",
    "    if rfc_df is not None:\n",
    "        e_df2=errorsOverviewPlot(rfc_df, \"RFC Exceptions Overview\\n\")\n",
    "        e_f_df['RFC']=e_df2.tail(1).transpose()[rfc_df.tail(1).index.max()]\n",
    "        print(str(ls_df.tail(1).index.max())+\" = \"+str(rfc_df.tail(1).index.max()))\n",
    "    \n",
    "    display(e_f_df)\n",
    "    \n",
    "    inputsls=int(ls_df.tail(1)['nr-inputs'].max())\n",
    "    \n",
    "    rfccap=' unique inputs'\n",
    "    if rfc_df is not None:\n",
    "        inputsrfc=int(rfc_df.tail(1)['nr-inputs'].max())\n",
    "        rfccap=' (Living Standard-based) and '+str(inputsrfc)+'(RFC-based) unique inputs'\n",
    "        print(str(ls_df.tail(1).index.max())+\" = \"+str(rfc_df.tail(1).index.max()))\n",
    "    caption='for run '+str(ls_df.tail(1).index.max())+' with '+str(inputsls)+rfccap\n",
    "    \n",
    "    print(fixCapitalization(e_f_df.sort_values(by='Living Standard').to_latex(column_format='lcc',float_format=\"{:.2f}%\".format), ['-exceptions', 'script', '.00'], ['', 'script ', '']))\n",
    "    print('\\caption[Parser error rates]{Parser error rates '+caption+'}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceExperimentResults(ls_df, ls_df_comp, rfc_df, rfc_df_comp, pdfnamesuffix, stepsize):\n",
    "    dfs={}\n",
    "    plots=[]\n",
    "    for parser in sorted(parsers):\n",
    "        dfs[parser], plot=compareGrammarResults(parser, ls_df, \"Living Standard\", rfc_df, \"RFC\")\n",
    "        plots+=[plot]\n",
    "\n",
    "    createMultiOverview(dfs, sorted(parsers), \"ov_detail\"+pdfnamesuffix+\".pdf\", True)\n",
    "    \n",
    "    print('rfc comp table')\n",
    "    print(create_comp_table(rfc_df_comp, rfc_df, stepsize))\n",
    "    print('ls comp table')\n",
    "    print(create_comp_table(ls_df_comp, ls_df, stepsize))\n",
    "\n",
    "    res_df=createMaxCovBarDiagram(dfs, \"ov_max_bar\"+pdfnamesuffix+\".pdf\")\n",
    "    createCovRunTable(res_df)\n",
    "\n",
    "    createComponentErrorPercentageTable(ls_df, ls_df_comp, rfc_df, rfc_df_comp)\n",
    "\n",
    "    createErrorPercentageTable(ls_df, rfc_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ls_df, ls_df_comp, rfc_df, rfc_df_comp=readAndAlignCSVs('./ls', './rfc', 'run_nr')\n",
    "\n",
    "\n",
    "produceExperimentResults(ls_df, ls_df_comp, rfc_df, rfc_df_comp, \"base\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Test Set Size Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "small_ls_df, small_ls_df_comp, small_rfc_df, small_rfc_df_comp=readAndAlignCSVs('./smallExp/ls', './smallExp/rfc', 'run_nr')\n",
    "\n",
    "produceExperimentResults(small_ls_df, small_ls_df_comp, small_rfc_df, small_rfc_df_comp, \"small\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Test Set Size Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceSingleGrammarExperimentResults(ls_df, ls_df_comp, stepsize, pdfnamesuffix):\n",
    "    dfs={}\n",
    "    plots=[]\n",
    "    \n",
    "    for parser in sorted(parsers):\n",
    "        dfs[parser], plot=compareGrammarResults(parser, ls_df, \"Living Standard\", None, \"\") \n",
    "        plots+=[plot]\n",
    "\n",
    "    createMultiOverview(dfs, sorted(parsers), \"ov_detail\"+pdfnamesuffix+\".pdf\", True)\n",
    "    \n",
    "    print('comp table')\n",
    "    print(create_comp_table(ls_df_comp, ls_df, stepsize))\n",
    "\n",
    "    res_df=createMaxCovBarDiagram(dfs, \"ov_max_bar\"+pdfnamesuffix+\".pdf\") #don't use bar diagram but use res_df\n",
    "    createCovRunTable(res_df)\n",
    "\n",
    "    createComponentErrorPercentageTable(ls_df, ls_df_comp, None, None)\n",
    "\n",
    "    createErrorPercentageTable(ls_df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "large_ls_df, large_ls_df_comp=readCSVs('./largeTestSetSize', indexcol='run_nr')\n",
    "produceSingleGrammarExperimentResults(large_ls_df, large_ls_df_comp, 1, \"large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
